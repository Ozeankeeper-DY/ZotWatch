"""Voyage AI embedding provider."""

import logging
from typing import Iterable

import numpy as np
import voyageai

from zotwatch.core.constants import VOYAGE_EMBEDDING_DIM
from zotwatch.core.exceptions import ConfigurationError

from .base import BaseEmbeddingProvider

logger = logging.getLogger(__name__)


class VoyageEmbedding(BaseEmbeddingProvider):
    """Voyage AI text embedding provider."""

    def __init__(
        self,
        model_name: str = "voyage-3.5",
        api_key: str = "",
        input_type: str = "document",
        batch_size: int = 128,
    ):
        self._model_name = model_name
        self.api_key = api_key
        self.input_type = input_type
        self.batch_size = batch_size
        self._client = None
        self._dimensions = VOYAGE_EMBEDDING_DIM

    @property
    def model_name(self) -> str:
        return self._model_name

    @property
    def dimensions(self) -> int:
        return self._dimensions

    def _get_client(self) -> voyageai.Client:
        """Get or create Voyage AI client."""
        if self._client is None:
            if not self.api_key:
                raise ConfigurationError("Voyage API key is required. Set VOYAGE_API_KEY environment variable.")
            self._client = voyageai.Client(api_key=self.api_key)
        return self._client

    def encode(self, texts: Iterable[str]) -> np.ndarray:
        """Encode texts to embeddings."""
        client = self._get_client()
        # Replace empty strings with placeholder (Voyage API rejects empty input)
        texts = [t.strip() if t and t.strip() else "[untitled]" for t in texts]
        total = len(texts)
        num_batches = (total + self.batch_size - 1) // self.batch_size
        logger.info("Encoding %d texts with %s (%d batches)", total, self._model_name, num_batches)

        all_embeddings = []
        for batch_idx, i in enumerate(range(0, total, self.batch_size)):
            batch = texts[i : i + self.batch_size]
            logger.info("  Batch %d/%d: encoding %d texts...", batch_idx + 1, num_batches, len(batch))
            result = client.embed(
                batch,
                model=self._model_name,
                input_type=self.input_type,
            )
            all_embeddings.extend(result.embeddings)

        embeddings = np.asarray(all_embeddings, dtype=np.float32)
        # L2 normalization for FAISS IndexFlatIP (inner product = cosine similarity)
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-12
        return embeddings / norms


__all__ = ["VoyageEmbedding"]
